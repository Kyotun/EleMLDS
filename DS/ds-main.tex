% !TEX program = pdflatex
% Data Science Part — Master Notes Template
% Compile: pdflatex main.tex (run twice for TOC links)

\documentclass[11pt,a4paper]{article}

% --------- Packages ----------
\usepackage[margin=2.2cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}

\usepackage{microtype}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, shapes.geometric}

% --------- Hyperref ----------
\hypersetup{
  colorlinks=true,
  linkcolor=blue!55!black,
  urlcolor=blue!55!black
}

% --------- Lists ----------
\setlist[itemize]{leftmargin=*, itemsep=2pt, topsep=4pt}
\setlist[enumerate]{leftmargin=*, itemsep=2pt, topsep=4pt}

% --------- Visual / Exam Boxes ----------
\tcbset{
  colback=white,
  colframe=black!25,
  arc=2mm,
  boxrule=0.6pt,
  left=1.2mm,right=1.2mm,top=1.2mm,bottom=1.2mm
}

\newtcolorbox{examlikelihood}[1]{
  title={Exam likelihood: #1},
  colframe=blue!55!black
}

\newtcolorbox{examfavorite}{
  title={Examiner favorite (what they love to ask)},
  colframe=red!65!black
}

\newtcolorbox{pitfall}{
  title={Common pitfall},
  colframe=orange!80!black
}

\newtcolorbox{cheatsheet}{
  title={Cheat sheet / must-memorize},
  colframe=green!55!black
}

\newtcolorbox{visualbox}{
  title={Visual (for your cortex)},
  colframe=purple!55!black
}

% --------- Teaching content hooks ----------
\makeatletter
\newcommand{\DefineTeach}[2]{\expandafter\def\csname Teach@#1\endcsname{#2}}
\newcommand{\UseTeach}[1]{\@ifundefined{Teach@#1}{}{\csname Teach@#1\endcsname}}
\makeatother

\input{teach.tex}

% Insert teaching blocks automatically after (sub)section headings.
\makeatletter
\let\oldsection\section
\renewcommand{\section}{\@ifstar{\TeachSectionStar}{\TeachSectionNoStar}}
\newcommand{\TeachSectionNoStar}{\@ifnextchar[{\TeachSectionOpt}{\TeachSectionPlain}}
\newcommand{\TeachSectionPlain}[1]{\oldsection{#1}\UseTeach{\thesection}}
\newcommand{\TeachSectionOpt}[2][]{\oldsection[#1]{#2}\UseTeach{\thesection}}
\newcommand{\TeachSectionStar}[1]{\oldsection*{#1}}

\let\oldsubsection\subsection
\renewcommand{\subsection}{\@ifstar{\TeachSubsectionStar}{\TeachSubsectionNoStar}}
\newcommand{\TeachSubsectionNoStar}{\@ifnextchar[{\TeachSubsectionOpt}{\TeachSubsectionPlain}}
\newcommand{\TeachSubsectionPlain}[1]{\oldsubsection{#1}\UseTeach{\thesubsection}}
\newcommand{\TeachSubsectionOpt}[2][]{\oldsubsection[#1]{#2}\UseTeach{\thesubsection}}
\newcommand{\TeachSubsectionStar}[1]{\oldsubsection*{#1}}

\let\oldsubsubsection\subsubsection
\renewcommand{\subsubsection}{\@ifstar{\TeachSubsubsectionStar}{\TeachSubsubsectionNoStar}}
\newcommand{\TeachSubsubsectionNoStar}{\@ifnextchar[{\TeachSubsubsectionOpt}{\TeachSubsubsectionPlain}}
\newcommand{\TeachSubsubsectionPlain}[1]{\oldsubsubsection{#1}\UseTeach{\thesubsubsection}}
\newcommand{\TeachSubsubsectionOpt}[2][]{\oldsubsubsection[#1]{#2}\UseTeach{\thesubsubsection}}
\newcommand{\TeachSubsubsectionStar}[1]{\oldsubsubsection*{#1}}
\makeatother

% --------- Title ----------
\title{\textbf{Elements of Machine Learning and Data Science}\\
\large Part I: Data Science — Exam Notes (Living Document)}
\author{Emir Pisirici}
\date{\today}

\begin{document}
\maketitle

\vspace{-3mm}
\begin{examlikelihood}{High (overall Data Science part)}
This document is structured to match the lecture topics exactly and is designed for adding
\textbf{exam-style notes}, \textbf{common traps}, and \textbf{visual summaries}.
\end{examlikelihood}

\tableofcontents
\newpage

% ============================================================
% 1) INTRODUCTION TO DATA SCIENCE
% ============================================================
\section{Introduction to Data Science}

\subsection{Introduction}
% --- Add your notes here ---

\subsection{Tabular Data}
% --- Add your notes here ---

\subsection{Data Science Process}
\begin{examlikelihood}{High}
Framework questions are easy to grade and strongly test ``big picture'' understanding.
\end{examlikelihood}

\begin{examfavorite}
Typical asks: \textbf{ETL vs ELT}, \textbf{CRISP-DM phases}, and mapping a scenario to the correct phase.
Also: where data leakage/bias lives (data understanding + evaluation).
\end{examfavorite}

\subsubsection{ETL vs ELT (Definitions + Differences)}
% --- Add your notes here ---
\begin{cheatsheet}
\textbf{ETL:} Extract $\rightarrow$ Transform $\rightarrow$ Load (transform before target).\\
\textbf{ELT:} Extract $\rightarrow$ Load $\rightarrow$ Transform (transform inside target platform).\\
\textbf{Key contrast:} where transformations happen; governance vs flexibility; raw history availability.
\end{cheatsheet}

\begin{pitfall}
People confuse ``ELT = no cleaning''. Wrong. It means cleaning happens \emph{after loading},
often in warehouse/lakehouse layers (staging $\rightarrow$ curated).
\end{pitfall}

\begin{visualbox}
\centering
\begin{tikzpicture}[
  node distance=9mm and 14mm,
  box/.style={draw, rounded corners, minimum width=18mm, minimum height=8mm, align=center},
  arrow/.style={-Latex, thick}
]
\node[box] (e1) {Extract};
\node[box, right=of e1] (t1) {Transform};
\node[box, right=of t1] (l1) {Load};
\draw[arrow] (e1) -- (t1);
\draw[arrow] (t1) -- (l1);
\node[below=6mm of t1] {\textbf{ETL}};

\node[box, below=18mm of e1] (e2) {Extract};
\node[box, right=of e2] (l2) {Load};
\node[box, right=of l2] (t2) {Transform};
\draw[arrow] (e2) -- (l2);
\draw[arrow] (l2) -- (t2);
\node[below=6mm of l2] {\textbf{ELT}};
\end{tikzpicture}
\end{visualbox}

\subsubsection{CRISP-DM}
% --- Add your notes here ---
\begin{cheatsheet}
\textbf{CRISP-DM:}
Business Understanding $\rightarrow$ Data Understanding $\rightarrow$ Data Preparation $\rightarrow$
Modeling $\rightarrow$ Evaluation $\rightarrow$ Deployment (iterative loops).
\end{cheatsheet}

\begin{visualbox}
\centering
\begin{tikzpicture}[
  crispstep/.style={draw, rounded corners, align=center, minimum width=32mm, minimum height=8mm},
  arrow/.style={-Latex, thick},
  node distance=7mm and 10mm
]
\node[crispstep] (b) {Business\\Understanding};
\node[crispstep, right=of b] (du) {Data\\Understanding};
\node[crispstep, right=of du] (dp) {Data\\Preparation};
\node[crispstep, below=of du] (m) {Modeling};
\node[crispstep, left=of m] (e) {Evaluation};
\node[crispstep, right=of m] (d) {Deployment};

\draw[arrow] (b) -- (du);
\draw[arrow] (du) -- (dp);
\draw[arrow] (dp) -- (m);
\draw[arrow] (m) -- (e);
\draw[arrow] (e) -- (b);

% Iteration arrows
% \draw[arrow] (e.north) .. controls +(0,10mm) and +(0,10mm) .. (du.north);
\draw[arrow] (m.south) .. controls +(0,-10mm) and +(0,-10mm) .. (dp.south);
\end{tikzpicture}
\end{visualbox}

\subsubsection{PDCA}
% --- Add your notes here ---
\begin{cheatsheet}
\textbf{PDCA:} Plan $\rightarrow$ Do $\rightarrow$ Check $\rightarrow$ Act (continuous improvement loop).
\end{cheatsheet}

\subsubsection{DMAIC}
% --- Add your notes here ---
\begin{cheatsheet}
\textbf{DMAIC:} Define $\rightarrow$ Measure $\rightarrow$ Analyze $\rightarrow$ Improve $\rightarrow$ Control.
Often used for process/quality improvement + monitoring and part of the Six Sigma methodology.
\end{cheatsheet}

\subsection{Data Types}
% --- Add your notes here ---

\subsection{Descriptive Statistics}
% --- Add your notes here ---

\subsection{Basic Visualizations}
% --- Add your notes here ---

\subsection{Feature Transformations}
% --- Add your notes here ---

\subsection{``How to lie with statistics''}
% --- Add your notes here ---

% ============================================================
% 2) DECISION TREES
% ============================================================
\newpage
\section{Decision Trees}

\subsection{Introduction to Decision Trees}

\subsection{Entropy and Information Gain}
\begin{examlikelihood}{Very High}
Almost guaranteed: compute entropy / information gain on a small dataset.
\end{examlikelihood}

% Placeholder sections (fill later)
\subsection{ID3 Algorithm}
\subsection{Pruning}
\subsection{Continuous Data (Threshold splits)}
\subsection{Ensembles (Bagging/Random Forest/Boosting)}

% ============================================================
% 3) CLUSTERING
% ============================================================
\newpage
\section{Clustering}

\subsection{Introduction to Unsupervised Learning}
\subsection{Introduction to Clustering}
\subsection{Similarity and Dissimilarity}
\subsection{K-means and K-medoids}
\subsection{Agglomerative Clustering}
\subsection{DBSCAN}
\subsection{Closing}

% ============================================================
% 4) FREQUENT ITEMSETS
% ============================================================
\newpage
\section{Frequent Itemsets}

\subsection{Introduction}
\subsection{Properties of Frequent Itemsets}
\subsection{Apriori Algorithm}
\subsection{FP-Growth Algorithm}

% ============================================================
% 5) ASSOCIATION RULES
% ============================================================
\newpage
\section{Association Rules}

\subsection{Introduction}
\subsection{Generating Association Rules}
\subsection{Evaluation (support, confidence, lift, conviction)}
\subsection{Applications}
\subsection{Simpson's Paradox}

% ============================================================
% 6) TIME SERIES
% ============================================================
\newpage
\section{Time Series}

\subsection{Temporal Data}
\subsection{Introduction to Time Series}
\subsection{Analysis}
\subsection{Forecasting}

% ============================================================
% END
% ============================================================
\end{document}
