\contentsline {section}{\numberline {1}Introduction to Data Science}{3}{section.1}%
\contentsline {subsection}{\numberline {1.1}Introduction}{3}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Tabular Data}{3}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Data Science Process}{3}{subsection.1.3}%
\contentsline {subsubsection}{\numberline {1.3.1}ETL vs ELT (Definitions + Differences)}{3}{subsubsection.1.3.1}%
\contentsline {subsubsection}{\numberline {1.3.2}CRISP-DM}{3}{subsubsection.1.3.2}%
\contentsline {subsubsection}{\numberline {1.3.3}PDCA}{4}{subsubsection.1.3.3}%
\contentsline {subsubsection}{\numberline {1.3.4}DMAIC}{4}{subsubsection.1.3.4}%
\contentsline {subsection}{\numberline {1.4}Data Types}{4}{subsection.1.4}%
\contentsline {subsection}{\numberline {1.5}Descriptive Statistics}{4}{subsection.1.5}%
\contentsline {subsection}{\numberline {1.6}Basic Visualizations}{4}{subsection.1.6}%
\contentsline {subsection}{\numberline {1.7}Feature Transformations}{4}{subsection.1.7}%
\contentsline {subsection}{\numberline {1.8}``How to lie with statistics''}{4}{subsection.1.8}%
\contentsline {section}{\numberline {2}Decision Trees}{5}{section.2}%
\contentsline {subsection}{\numberline {2.1}Introduction to Decision Trees}{5}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Entropy and Information Gain}{5}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}ID3 Algorithm}{5}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Pruning}{5}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}Continuous Data (Threshold splits)}{5}{subsection.2.5}%
\contentsline {subsection}{\numberline {2.6}Ensembles (Bagging/Random Forest/Boosting)}{5}{subsection.2.6}%
\contentsline {section}{\numberline {3}Clustering}{6}{section.3}%
\contentsline {subsection}{\numberline {3.1}Introduction to Unsupervised Learning}{6}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Introduction to Clustering}{6}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Similarity and Dissimilarity}{6}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}K-means and K-medoids}{6}{subsection.3.4}%
\contentsline {subsection}{\numberline {3.5}Agglomerative Clustering}{6}{subsection.3.5}%
\contentsline {subsection}{\numberline {3.6}DBSCAN}{6}{subsection.3.6}%
\contentsline {subsection}{\numberline {3.7}Closing}{6}{subsection.3.7}%
\contentsline {section}{\numberline {4}Frequent Itemsets}{7}{section.4}%
\contentsline {subsection}{\numberline {4.1}Introduction}{7}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Properties of Frequent Itemsets}{7}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Apriori Algorithm}{7}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}FP-Growth Algorithm}{7}{subsection.4.4}%
\contentsline {section}{\numberline {5}Association Rules}{8}{section.5}%
\contentsline {subsection}{\numberline {5.1}Introduction}{8}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Generating Association Rules}{8}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Evaluation (support, confidence, lift, conviction)}{8}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Applications}{8}{subsection.5.4}%
\contentsline {subsection}{\numberline {5.5}Simpson's Paradox}{8}{subsection.5.5}%
\contentsline {section}{\numberline {6}Time Series}{9}{section.6}%
\contentsline {subsection}{\numberline {6.1}Temporal Data}{9}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Introduction to Time Series}{9}{subsection.6.2}%
\contentsline {subsection}{\numberline {6.3}Analysis}{9}{subsection.6.3}%
\contentsline {subsection}{\numberline {6.4}Forecasting}{9}{subsection.6.4}%
